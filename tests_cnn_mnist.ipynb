{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jaxmao.layers import Conv2D, Dense, BatchNorm, ReLU, Flatten, StableSoftmax\n",
    "from jaxmao.modules import Module\n",
    "from jaxmao.optimizers import GradientDescent\n",
    "from jaxmao.losses import CategoricalCrossEntropy\n",
    "from jaxmao.metrics import Accuracy\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1697767609.564137   10933 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 8, 8, 1), (360, 8, 8, 1), (1437,), (360,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_digits()\n",
    "image, label = data['images'], data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(image, label, test_size=0.2, random_state=seed)\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "y_train_enc = enc.fit_transform(np.expand_dims(y_train, axis=1))\n",
    "y_test_enc = enc.transform(np.expand_dims(y_test, axis=1))\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 8, 8, 16), jaxlib.xla_extension.ArrayImpl, dict)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DigitClassifier(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add('conv1', Conv2D(1, 16, (3, 3), 1))\n",
    "        self.add('flatten', Flatten())\n",
    "        self.add('bn1', BatchNorm(16))\n",
    "        self.add('fc1', Dense(16, 16, activation=ReLU()))\n",
    "        self.add('bn2', BatchNorm(16))\n",
    "        self.add('fc2', Dense(16, 10, activation=StableSoftmax()))\n",
    "    \n",
    "    def forward(self, params, x, state):\n",
    "        x, state = self.forward_with_state(params, x, 'conv1', state)\n",
    "        # x, state = self.forward_with_state(params, x, 'flatten', state)\n",
    "        x, state = self.forward_with_state(params, x, 'bn1', state)\n",
    "        # x, state = self.forward_with_sta  te(params, x, 'fc1', state)\n",
    "        # x, state = self.forward_with_state(params, x, 'bn2', state)\n",
    "        # x, state = self.forward_with_state(params, x, 'fc2', state)\n",
    "        return x, state\n",
    "    \n",
    "clf = DigitClassifier()\n",
    "clf.init_params(key)\n",
    "\n",
    "clf.forward = jax.jit(clf.forward)\n",
    "clf.pure_forward = jax.jit(clf.pure_forward)\n",
    "\n",
    "out, state = clf.pure_forward(clf.params, X_test, clf.state)\n",
    "out.shape, type(out), type(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': (1, 16), 'beta': (16,)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.layers['bn1'].shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "criteria = CategoricalCrossEntropy()\n",
    "criteria.calculate_loss = jax.jit(criteria.calculate_loss)\n",
    "def loss_fn(model, params, x_true, y_true, state,\n",
    "            criteria\n",
    "            ):\n",
    "    y_pred, new_state = model.pure_forward(params, x_true, state)\n",
    "    loss = criteria.calculate_loss(y_pred, y_true)\n",
    "    return loss, new_state\n",
    "\n",
    "val_grad_loss_fn = jax.value_and_grad(loss_fn, argnums=1, has_aux=True)\n",
    "def training_loop(\n",
    "    model, optimizer, x_true, y_true,\n",
    "    epochs, lr=0.01, batch_size=16\n",
    "):\n",
    "    num_batch = len(x_true) // batch_size \n",
    "    for epoch in range(epochs):\n",
    "        losses = 0.0\n",
    "        x_true, y_true = shuffle(x_true, y_true)\n",
    "        for n in range(num_batch):\n",
    "            batch_x = x_true[n*batch_size:(n+1)*batch_size]\n",
    "            batch_y = y_true[n*batch_size:(n+1)*batch_size]\n",
    "            (loss, new_state), gradients = val_grad_loss_fn(model, model.params, \n",
    "                                                            batch_x, \n",
    "                                                            batch_y, \n",
    "                                                            model.state, \n",
    "                                                            criteria)\n",
    "            losses = losses + loss\n",
    "            model.params, optim_state = optimizer.step(model.params, gradients, lr=lr)\n",
    "            model.update_state(new_state)\n",
    "        \n",
    "        accuracy = Accuracy()(model(model.params, batch_x), batch_y.argmax(axis=1))\n",
    "        print('epoch {}: {}, {}'.format(epoch, losses/num_batch, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible shapes for broadcasting: shapes=[(16, 10), (16, 8, 8, 16)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxlab/lib/python3.11/site-packages/jax/_src/util.py:263\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 263\u001b[0m   \u001b[39mreturn\u001b[39;00m cached(config\u001b[39m.\u001b[39;49m_trace_context(), \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxlab/lib/python3.11/site-packages/jax/_src/util.py:256\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.cached\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mlru_cache(max_size)\n\u001b[1;32m    255\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcached\u001b[39m(_, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 256\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxlab/lib/python3.11/site-packages/jax/_src/lax/lax.py:152\u001b[0m, in \u001b[0;36m_broadcast_shapes_cached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39m@cache\u001b[39m()\n\u001b[1;32m    151\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_broadcast_shapes_cached\u001b[39m(\u001b[39m*\u001b[39mshapes: \u001b[39mtuple\u001b[39m[\u001b[39mint\u001b[39m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[\u001b[39mint\u001b[39m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]:\n\u001b[0;32m--> 152\u001b[0m   \u001b[39mreturn\u001b[39;00m _broadcast_shapes_uncached(\u001b[39m*\u001b[39;49mshapes)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxlab/lib/python3.11/site-packages/jax/_src/lax/lax.py:168\u001b[0m, in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m result_shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIncompatible shapes for broadcasting: shapes=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(shapes)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    169\u001b[0m \u001b[39mreturn\u001b[39;00m result_shape\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: shapes=[(16, 10), (16, 8, 8, 16)]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m lr \u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m training_loop(clf, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m               optimizer, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m               X_train, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m               y_train_enc, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m               epochs\u001b[39m=\u001b[39;49mepochs, lr\u001b[39m=\u001b[39;49mlr, batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m               )\n",
      "\u001b[1;32m/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m batch_x \u001b[39m=\u001b[39m x_true[n\u001b[39m*\u001b[39mbatch_size:(n\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mbatch_size]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m batch_y \u001b[39m=\u001b[39m y_true[n\u001b[39m*\u001b[39mbatch_size:(n\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mbatch_size]\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m (loss, new_state), gradients \u001b[39m=\u001b[39m val_grad_loss_fn(model, model\u001b[39m.\u001b[39;49mparams, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m                                                 batch_x, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m                                                 batch_y, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m                                                 model\u001b[39m.\u001b[39;49mstate, \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m                                                 criteria)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m losses \u001b[39m=\u001b[39m losses \u001b[39m+\u001b[39m loss\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m model\u001b[39m.\u001b[39mparams, optim_state \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mstep(model\u001b[39m.\u001b[39mparams, gradients, lr\u001b[39m=\u001b[39mlr)\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "\u001b[1;32m/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb Cell 6\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_fn\u001b[39m(model, params, x_true, y_true, state,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m             criteria\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m             ):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     y_pred, new_state \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpure_forward(params, x_true, state)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     loss \u001b[39m=\u001b[39m criteria\u001b[39m.\u001b[39;49mcalculate_loss(y_pred, y_true)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jaxmao/jaxmao_branches/JaxMao/tests_cnn_mnist.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m loss, new_state\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/jaxmao_branches/JaxMao/jaxmao/losses.py:16\u001b[0m, in \u001b[0;36mCategoricalCrossEntropy.calculate_loss\u001b[0;34m(self, y_pred, y_true)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_loss\u001b[39m(\u001b[39mself\u001b[39m, y_pred, y_true):\n\u001b[1;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mjnp\u001b[39m.\u001b[39mmean(\n\u001b[0;32m---> 16\u001b[0m         jnp\u001b[39m.\u001b[39msum(y_true\u001b[39m*\u001b[39;49mjnp\u001b[39m.\u001b[39;49mlog(y_pred))\n\u001b[1;32m     17\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxlab/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:728\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mop\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 728\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maval, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mname\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxlab/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:256\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    254\u001b[0m args \u001b[39m=\u001b[39m (other, \u001b[39mself\u001b[39m) \u001b[39mif\u001b[39;00m swap \u001b[39melse\u001b[39;00m (\u001b[39mself\u001b[39m, other)\n\u001b[1;32m    255\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 256\u001b[0m   \u001b[39mreturn\u001b[39;00m binary_op(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    257\u001b[0m \u001b[39m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(other) \u001b[39min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxlab/lib/python3.11/site-packages/jax/_src/numpy/ufuncs.py:96\u001b[0m, in \u001b[0;36m_maybe_bool_binop.<locals>.fn\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(x1, x2, \u001b[39m/\u001b[39m):\n\u001b[0;32m---> 96\u001b[0m   x1, x2 \u001b[39m=\u001b[39m promote_args(numpy_fn\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m, x1, x2)\n\u001b[1;32m     97\u001b[0m   \u001b[39mreturn\u001b[39;00m lax_fn(x1, x2) \u001b[39mif\u001b[39;00m x1\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mbool_ \u001b[39melse\u001b[39;00m bool_lax_fn(x1, x2)\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxlab/lib/python3.11/site-packages/jax/_src/numpy/util.py:358\u001b[0m, in \u001b[0;36mpromote_args\u001b[0;34m(fun_name, *args)\u001b[0m\n\u001b[1;32m    356\u001b[0m check_arraylike(fun_name, \u001b[39m*\u001b[39margs)\n\u001b[1;32m    357\u001b[0m _check_no_float0s(fun_name, \u001b[39m*\u001b[39margs)\n\u001b[0;32m--> 358\u001b[0m \u001b[39mreturn\u001b[39;00m promote_shapes(fun_name, \u001b[39m*\u001b[39;49mpromote_dtypes(\u001b[39m*\u001b[39;49margs))\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxlab/lib/python3.11/site-packages/jax/_src/numpy/util.py:247\u001b[0m, in \u001b[0;36mpromote_shapes\u001b[0;34m(fun_name, *args)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_numpy_rank_promotion \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    246\u001b[0m   _rank_promotion_warning_or_error(fun_name, shapes)\n\u001b[0;32m--> 247\u001b[0m result_rank \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(lax\u001b[39m.\u001b[39;49mbroadcast_shapes(\u001b[39m*\u001b[39;49mshapes))\n\u001b[1;32m    248\u001b[0m \u001b[39mreturn\u001b[39;00m [_broadcast_to(arg, (\u001b[39m1\u001b[39m,) \u001b[39m*\u001b[39m (result_rank \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(shp)) \u001b[39m+\u001b[39m shp)\n\u001b[1;32m    249\u001b[0m         \u001b[39mfor\u001b[39;00m arg, shp \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(args, shapes)]\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxlab/lib/python3.11/site-packages/jax/_src/lax/lax.py:168\u001b[0m, in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    166\u001b[0m result_shape \u001b[39m=\u001b[39m _try_broadcast_shapes(shape_list)\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m result_shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIncompatible shapes for broadcasting: shapes=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(shapes)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    169\u001b[0m \u001b[39mreturn\u001b[39;00m result_shape\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: shapes=[(16, 10), (16, 8, 8, 16)]"
     ]
    }
   ],
   "source": [
    "optimizer = GradientDescent()\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "\n",
    "training_loop(clf, \n",
    "              optimizer, \n",
    "              X_train, \n",
    "              y_train_enc, \n",
    "              epochs=epochs, lr=lr, batch_size=16\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf(clf.params, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.9638889, dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy().calculate(y_pred.argmax(axis=1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = np.random.randint(0, len(X_test))\n",
    "plt.imshow(X_test[index])\n",
    "plt.title(f'{y_test[index]}, {y_pred[index].argmax()}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using .fit()!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DigitClassifier()\n",
    "clf.init_params(key)\n",
    "\n",
    "out = clf(clf.params, X_test)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: Loss 3.0322628021240234; accuracy: 0.9751420617103577\n",
      "epoch 1: Loss 3.216646432876587; accuracy: 0.96875\n",
      "epoch 2: Loss 2.399807929992676; accuracy: 0.9808238744735718\n",
      "epoch 3: Loss 1.7255582809448242; accuracy: 0.9850852489471436\n",
      "epoch 4: Loss 1.9668234586715698; accuracy: 0.9822443723678589\n"
     ]
    }
   ],
   "source": [
    "clf.compile(\n",
    "    loss_fn=CategoricalCrossEntropy(),\n",
    "    optimizer=GradientDescent(),\n",
    "    metrics=Accuracy()\n",
    ")\n",
    "clf.fit(X_train, y_train_enc, lr=0.01, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
