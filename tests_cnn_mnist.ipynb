{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jaxmao.layers import Dense, BatchNorm, ReLU, Flatten, StableSoftmax\n",
    "from jaxmao.modules import Module\n",
    "from jaxmao.optimizers import GradientDescent\n",
    "from jaxmao.losses import CategoricalCrossEntropy\n",
    "from jaxmao.metrics import Accuracy\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1697726432.478044  316748 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 8, 8), (360, 8, 8), (1437,), (360,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_digits()\n",
    "image, label = data['images'], data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(image, label, test_size=0.2, random_state=seed)\n",
    "\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "y_train_enc = enc.fit_transform(np.expand_dims(y_train, axis=1))\n",
    "y_test_enc = enc.transform(np.expand_dims(y_test, axis=1))\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 10), jaxlib.xla_extension.ArrayImpl, dict)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DigitClassifier(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add('flatten', Flatten())\n",
    "        self.add('bn1', BatchNorm(64))\n",
    "        self.add('fc1', Dense(64, 16, activation=ReLU()))\n",
    "        self.add('bn2', BatchNorm(16))\n",
    "        self.add('fc2', Dense(16, 10, activation=StableSoftmax()))\n",
    "    \n",
    "    def forward(self, params, x, state):\n",
    "        x, state = self.forward_with_state(params, x, 'flatten', state)\n",
    "        x, state = self.forward_with_state(params, x, 'bn1', state)\n",
    "        x, state = self.forward_with_state(params, x, 'fc1', state)\n",
    "        x, state = self.forward_with_state(params, x, 'bn2', state)\n",
    "        x, state = self.forward_with_state(params, x, 'fc2', state)\n",
    "        return x, state\n",
    "    \n",
    "clf = DigitClassifier()\n",
    "clf.init_params(key)\n",
    "clf.forward = jax.jit(clf.forward)\n",
    "clf.pure_forward = jax.jit(clf.pure_forward)\n",
    "\n",
    "out, state = clf.pure_forward(clf.params, X_test, clf.state)\n",
    "out.shape, type(out), type(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.01130079, 0.05852171, 0.11489712, ..., 0.13720518, 0.06192375,\n",
       "        0.29072276],\n",
       "       [0.06010712, 0.05115694, 0.10832112, ..., 0.08855952, 0.1627044 ,\n",
       "        0.1572643 ],\n",
       "       [0.32594135, 0.09793901, 0.01010408, ..., 0.00661695, 0.00264588,\n",
       "        0.02289665],\n",
       "       ...,\n",
       "       [0.04531535, 0.05515421, 0.07712824, ..., 0.15537082, 0.0431489 ,\n",
       "        0.0595728 ],\n",
       "       [0.05300081, 0.1229734 , 0.26876947, ..., 0.09718218, 0.02225027,\n",
       "        0.05437118],\n",
       "       [0.20079541, 0.10078777, 0.08970465, ..., 0.06058684, 0.01616533,\n",
       "        0.03552077]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, s = jax.jit(clf.pure_forward)(clf.params, X_test, clf.state)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "criteria = CategoricalCrossEntropy()\n",
    "criteria.calculate_loss = jax.jit(criteria.calculate_loss)\n",
    "def loss_fn(model, params, x_true, y_true, state,\n",
    "            criteria\n",
    "            ):\n",
    "    y_pred, new_state = model.pure_forward(params, x_true, state)\n",
    "    loss = criteria.calculate_loss(y_pred, y_true)\n",
    "    return loss, new_state\n",
    "\n",
    "val_grad_loss_fn = jax.value_and_grad(loss_fn, argnums=1, has_aux=True)\n",
    "def training_loop(\n",
    "    model, optimizer, x_true, y_true,\n",
    "    epochs, lr=0.01, batch_size=16\n",
    "):\n",
    "    num_batch = len(x_true) // batch_size \n",
    "    for epoch in range(epochs):\n",
    "        losses = 0.0\n",
    "        x_true, y_true = shuffle(x_true, y_true)\n",
    "        for n in range(num_batch):\n",
    "            batch_x = x_true[n*batch_size:(n+1)*batch_size]\n",
    "            batch_y = y_true[n*batch_size:(n+1)*batch_size]\n",
    "            (loss, new_state), gradients = val_grad_loss_fn(model, model.params, \n",
    "                                                            batch_x, \n",
    "                                                            batch_y, \n",
    "                                                            model.state, \n",
    "                                                            criteria)\n",
    "            losses = losses + loss\n",
    "            model.params, optim_state = optimizer.step(model.params, gradients, lr=lr)\n",
    "            model.update_state(new_state)\n",
    "        \n",
    "        accuracy = Accuracy()(model(model.params, batch_x), batch_y.argmax(axis=1))\n",
    "        print('epoch {}: {}, {}'.format(epoch, losses/num_batch, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: 13.377989768981934, 1.0\n",
      "epoch 1: 4.775639057159424, 0.9375\n",
      "epoch 2: 3.6955363750457764, 0.9375\n",
      "epoch 3: 3.335810661315918, 1.0\n",
      "epoch 4: 3.0658586025238037, 1.0\n",
      "epoch 5: 2.5833990573883057, 1.0\n",
      "epoch 6: 2.2140393257141113, 1.0\n",
      "epoch 7: 2.215319871902466, 0.9375\n",
      "epoch 8: 2.280287742614746, 1.0\n",
      "epoch 9: 1.6045345067977905, 1.0\n"
     ]
    }
   ],
   "source": [
    "optimizer = GradientDescent()\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "\n",
    "training_loop(clf, \n",
    "              optimizer, \n",
    "              X_train, \n",
    "              y_train_enc, \n",
    "              epochs=epochs, lr=lr, batch_size=16\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf(clf.params, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.9638889, dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy().calculate(y_pred.argmax(axis=1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = np.random.randint(0, len(X_test))\n",
    "plt.imshow(X_test[index])\n",
    "plt.title(f'{y_test[index]}, {y_pred[index].argmax()}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using .fit()!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DigitClassifier()\n",
    "clf.init_params(key)\n",
    "\n",
    "out = clf(clf.params, X_test)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: Loss 3.0322628021240234; accuracy: 0.9751420617103577\n",
      "epoch 1: Loss 3.216646432876587; accuracy: 0.96875\n",
      "epoch 2: Loss 2.399807929992676; accuracy: 0.9808238744735718\n",
      "epoch 3: Loss 1.7255582809448242; accuracy: 0.9850852489471436\n",
      "epoch 4: Loss 1.9668234586715698; accuracy: 0.9822443723678589\n"
     ]
    }
   ],
   "source": [
    "clf.compile(\n",
    "    loss_fn=CategoricalCrossEntropy(),\n",
    "    optimizer=GradientDescent(),\n",
    "    metrics=Accuracy()\n",
    ")\n",
    "clf.fit(X_train, y_train_enc, lr=0.01, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
