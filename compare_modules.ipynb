{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1698063410.970257  134056 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n",
      "2023-10-23 19:16:50.990324: E external/xla/xla/stream_executor/cuda/cuda_driver.cc:276] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-10-23 19:16:51.298098: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-23 19:16:51.298187: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-23 19:16:51.298222: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.devices() : [CpuDevice(id=0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 19:16:52.371070: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.config.list_physical_devices():  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 19:16:53.265906: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "import jaxmao\n",
    "from jaxmao.layers import Conv2D, SimpleDense, Dense, BatchNorm, ReLU, Flatten, StableSoftmax, BatchNorm2D, DepthwiseConv2D, Activation\n",
    "from jaxmao.modules import Module\n",
    "from jaxmao.optimizers import GradientDescent\n",
    "from jaxmao.losses import CategoricalCrossEntropy\n",
    "from jaxmao.metrics import Accuracy, Precision, Recall\n",
    "\n",
    "print('jax.devices() :', jax.devices())\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "print('tf.config.list_physical_devices(): ', tf.config.list_physical_devices())\n",
    "\n",
    "seed = 42\n",
    "key = jax.random.PRNGKey(seed)\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_enough(A, B, eps=1e-5):\n",
    "    return np.less_equal(np.abs(A - B), eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jax.grad vs tf.GradientTape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX Gradient: [ 4.  10.8]\n",
      "TensorFlow Gradient: [ 4.  10.8]\n",
      "Are they close enough? [ True  True]\n"
     ]
    }
   ],
   "source": [
    "# Define the function f(x) = x^2\n",
    "def jax_function(x):\n",
    "    return jax.lax.pow(x, 2)\n",
    "\n",
    "def tf_function(x):\n",
    "    return tf.pow(x, 2)\n",
    "\n",
    "input = [2.0, 5.4]\n",
    "\n",
    "# Compute the gradient using JAX\n",
    "jax_grad = jax.grad(jax_function)\n",
    "x_jax = jnp.array(input)\n",
    "grad_jax = jax.vmap(jax_grad)(x_jax)\n",
    "\n",
    "# Compute the gradient using TensorFlow\n",
    "x_tf = tf.Variable(input, dtype=tf.float32)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x_tf)\n",
    "    y_tf = tf_function(x_tf)\n",
    "grad_tf = tape.gradient(y_tf, x_tf).numpy()\n",
    "\n",
    "# Compare\n",
    "print(\"JAX Gradient:\", grad_jax)\n",
    "print(\"TensorFlow Gradient:\", grad_tf)\n",
    "print(\"Are they close enough?\", np.isclose(grad_jax, grad_tf, atol=1e-6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.random.normal(2, 4, (200, 8, 8, 1)).astype('float32')\n",
    "y_train = np.random.randint(0, 10, (200,)).astype('float32')\n",
    "y_train_enc = np.array(\n",
    "    jax.nn.one_hot(y_train, num_classes=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 1, 4)         45        \n",
      "(256, 128)           384       \n",
      "(128, 32)            160       \n",
      "(32, 10)             42        \n",
      "layer                output shape         #'s params           #'s states          \n",
      "bn1                  (4, 8, 8, 1)         2                    0                   \n",
      "conv1                (4, 8, 8, 4)         40                   0                   \n",
      "flatten              (4, 256)             0                    0                   \n",
      "dense1               (4, 128)             32896                0                   \n",
      "dense2               (4, 32)              4128                 0                   \n",
      "dense3               (4, 10)              330                  0                   \n",
      "\n",
      "total parameters: 37396\n",
      "\n",
      "\n",
      "\n",
      "Model: \"keras_denseMNIST\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (Batch  (None, 8, 8, 1)           4         \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 8, 8, 4)           40        \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37398 (146.09 KB)\n",
      "Trainable params: 37396 (146.08 KB)\n",
      "Non-trainable params: 2 (8.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class DenseMNISTClasifier(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add('bn1', jaxmao.layers.BatchNorm2D(1, momentum=0.99, eps=1e-5))\n",
    "        self.add('conv1', jaxmao.layers.Conv2D(1, 4, (3, 3), (1,1), 'relu', weights_initializer=jaxmao.initializers.GlorotNormal()))\n",
    "        self.add('flatten', jaxmao.layers.Flatten())\n",
    "        self.add('dense1', jaxmao.layers.Dense(8*8*4, 128, 'relu', weights_initializer=jaxmao.initializers.GlorotNormal()))\n",
    "        self.add('dense2', jaxmao.layers.Dense(128, 32, 'relu', weights_initializer=jaxmao.initializers.GlorotNormal()))\n",
    "        self.add('dense3', jaxmao.layers.Dense(32, 10, 'softmax', weights_initializer=jaxmao.initializers.GlorotNormal()))\n",
    "    \n",
    "    def forward(self, params, x, state):\n",
    "        x, state = self.apply(params, x, 'bn1', state)\n",
    "        x, state = self.apply(params, x, 'conv1', state)\n",
    "        x, state = self.apply(params, x, 'flatten', state)\n",
    "        x, state = self.apply(params, x, 'dense1', state)\n",
    "        x, state = self.apply(params, x, 'dense2', state)\n",
    "        x, state = self.apply(params, x, 'dense3', state)\n",
    "        return x, state\n",
    "    \n",
    "jaxmao_model = DenseMNISTClasifier()\n",
    "jaxmao_model.init_params(key)\n",
    "summary = jaxmao_model.summarize(input_shape=(4, 8, 8, 1))\n",
    "\n",
    "print('\\n\\n')\n",
    "# Initialize the Sequential model\n",
    "keras_model = keras.Sequential(name='keras_denseMNIST')\n",
    "\n",
    "# Add layers to the keras_model\n",
    "keras_model.add(keras.layers.BatchNormalization(momentum=0.99, input_shape=(8, 8, 1), epsilon=1e-5))\n",
    "keras_model.add(keras.layers.Conv2D(filters=4, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'))\n",
    "keras_model.add(keras.layers.Flatten())\n",
    "keras_model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "keras_model.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "keras_model.add(keras.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "# Summary of the keras_model to show the architecture\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (jaxmao_layer, keras_layer) in enumerate(zip(jaxmao_model.layers.values(), keras_model.layers)):\n",
    "    if isinstance(jaxmao_layer, jaxmao.layers.BatchNorm):\n",
    "        keras_model.layers[index].set_weights(([np.array(jaxmao_layer.params['gamma']), \n",
    "                                                np.array(jaxmao_layer.params['beta']), \n",
    "                                                np.array(jaxmao_layer.state['running_mean']), \n",
    "                                                np.array(jaxmao_layer.state['running_var'])\n",
    "                                                ]))\n",
    "    elif isinstance(jaxmao_layer, jaxmao.layers.Conv2D):\n",
    "        keras_model.layers[index].set_weights([np.array(value) for value in jaxmao_layer.params['conv2d/simple_conv2d'].values()])\n",
    "        # TODO if the Conv2D has batchnorm.\n",
    "    elif isinstance(jaxmao_layer, jaxmao.layers.Flatten):\n",
    "        pass\n",
    "    elif isinstance(jaxmao_layer, jaxmao.layers.Dense):\n",
    "        keras_model.layers[index].set_weights([np.array(value) for value in jaxmao_layer.params['dense/simple_dense'].values()])\n",
    "        # TODO if the Dense has batchnorm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1999)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_prediction1 = close_enough(keras_model(X_train).numpy(), jaxmao_model(jaxmao_model.params, X_train), 1e-7)\n",
    "np.prod(close_prediction1.shape), close_prediction1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(2.952032, dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = jaxmao.losses.CategoricalCrossEntropy('mean_over_batch_size')\n",
    "optimizer = jaxmao.optimizers.GradientDescent(lr=0.01, params=jaxmao_model.params)\n",
    "\n",
    "def _loss_fnx(pure_forward, params, x, y, state):\n",
    "    y_pred, new_state = pure_forward(params, x, state)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    return loss, new_state\n",
    "\n",
    "loss_and_grad = jax.value_and_grad(_loss_fnx, argnums=1, has_aux=True)\n",
    "# (loss, new_state), gradients = jax.block_until_ready(\n",
    "#     loss_and_grad(jaxmao_model.pure_forward, jaxmao_model.params, X_train, y_train_enc, jaxmao_model.state)\n",
    "# )\n",
    "loss_fn(jaxmao_model(jaxmao_model.params, X_train), y_train_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(2.952032, dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(np.array(keras_model(X_train)), y_train_enc) # keras model, jaxmao loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9520326"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.losses.CategoricalCrossentropy(reduction='sum_over_batch_size')(y_train_enc, keras_model(X_train)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9520326"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.losses.CategoricalCrossentropy(reduction='sum_over_batch_size')(y_train_enc, jaxmao_model(jaxmao_model.params, X_train)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JaxMao SGD fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss: 2.642361879348755, accuracy: 0.155\n",
      "epoch 2: loss: 2.286381721496582, accuracy: 0.225\n",
      "epoch 3: loss: 2.1648850440979004, accuracy: 0.31\n",
      "epoch 4: loss: 2.068301200866699, accuracy: 0.355\n",
      "epoch 5: loss: 1.961280107498169, accuracy: 0.42\n",
      "epoch 6: loss: 1.839827537536621, accuracy: 0.48\n",
      "epoch 7: loss: 1.701788306236267, accuracy: 0.555\n",
      "epoch 8: loss: 1.5397034883499146, accuracy: 0.615\n",
      "epoch 9: loss: 1.363107442855835, accuracy: 0.695\n",
      "epoch 10: loss: 1.1714884042739868, accuracy: 0.79\n",
      "epoch 11: loss: 0.9792134165763855, accuracy: 0.825\n",
      "epoch 12: loss: 0.7859901189804077, accuracy: 0.875\n",
      "epoch 13: loss: 0.6146777272224426, accuracy: 0.915\n",
      "epoch 14: loss: 0.46759486198425293, accuracy: 0.93\n",
      "epoch 15: loss: 0.3600350618362427, accuracy: 0.96\n",
      "epoch 16: loss: 0.2795087695121765, accuracy: 0.975\n",
      "epoch 17: loss: 0.21337072551250458, accuracy: 0.99\n",
      "epoch 18: loss: 0.16679050028324127, accuracy: 0.99\n",
      "epoch 19: loss: 0.13324476778507233, accuracy: 0.99\n",
      "epoch 20: loss: 0.10774543136358261, accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 10\n",
    "NUM_BATCHES = len(X_train) // BATCH_SIZE\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = 0.0\n",
    "    # we can shuffle training set here\n",
    "    for num_batch in range(NUM_BATCHES):\n",
    "        i_index = num_batch*BATCH_SIZE\n",
    "        e_index = (num_batch+1)*BATCH_SIZE\n",
    "        batch_x = X_train[i_index: e_index]\n",
    "        batch_y = y_train_enc[i_index: e_index]\n",
    "        \n",
    "        (loss, new_state), gradients = loss_and_grad(jaxmao_model.pure_forward, jaxmao_model.params, \n",
    "                                                     batch_x, batch_y, jaxmao_model.state)\n",
    "        jaxmao_model.params, optimizer.state = optimizer(jaxmao_model.params, gradients, optimizer.state)\n",
    "        jaxmao_model.update_state(new_state)\n",
    "        \n",
    "        losses += loss\n",
    "\n",
    "    pred = jaxmao_model(jaxmao_model.params, X_train)    \n",
    "    print('epoch {}: loss: {}, accuracy: {}'.format(epoch+1, losses/NUM_BATCHES, accuracy_score(y_train, pred.argmax(axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras SGD fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 5ms/step - loss: 2.3482 - accuracy: 0.1000\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2.3129 - accuracy: 0.1100\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2.2858 - accuracy: 0.1400\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2.2628 - accuracy: 0.1500\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2.2422 - accuracy: 0.1550\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.2220 - accuracy: 0.1800\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.2016 - accuracy: 0.1900\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.1803 - accuracy: 0.2100\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2.1576 - accuracy: 0.2200\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.1333 - accuracy: 0.2350\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.1054 - accuracy: 0.2700\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.0747 - accuracy: 0.3050\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.0403 - accuracy: 0.3250\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 2.0016 - accuracy: 0.3550\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.9583 - accuracy: 0.3850\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.9084 - accuracy: 0.4150\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.8527 - accuracy: 0.4300\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.7910 - accuracy: 0.4650\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.7201 - accuracy: 0.5150\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.6428 - accuracy: 0.5350\n"
     ]
    }
   ],
   "source": [
    "keras_model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.01), \n",
    "                    loss=keras.losses.CategoricalCrossentropy(reduction='sum_over_batch_size'), \n",
    "                    metrics=['accuracy'])\n",
    "history = keras_model.fit(X_train, y_train_enc, epochs=20, batch_size=10, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
