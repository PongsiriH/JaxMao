{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jaxmao/jaxmao_branches/JaxMao/')\n",
    "sys.path.append('/home/jaxmao/jaxmao_branches/JaxMao/jaxmao')\n",
    "\n",
    "import jax\n",
    "from jaxmao.modules import Module\n",
    "from jaxmao.layers import Dense\n",
    "from jaxmao.losses import CategoricalCrossEntropy\n",
    "from jaxmao.optimizers import GradientDescent\n",
    "from jaxmao.utils_struct import _check_dict_ids\n",
    "\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1698215200.508901   37071 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n"
     ]
    }
   ],
   "source": [
    "images, targets = load_digits(return_X_y=True)\n",
    "\n",
    "images = images / images.max()\n",
    "targets_enc = jax.nn.one_hot(targets, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = Dense(64, 32, activation='relu', batch_norm=True) # Dense apply fc-bn-activ\n",
    "        self.dense2 = Dense(32, 10, activation='softmax', batch_norm=True)\n",
    "\n",
    "    def pure_forward(self, params, x, state):\n",
    "        x, state = self.forward(self.dense1, params, x, state)\n",
    "        x, state = self.forward(self.dense2, params, x, state)\n",
    "        return x, state\n",
    "    \n",
    "    \"\"\" equivalent\n",
    "    def pure_forward(self, params, x, state):\n",
    "        x, state['dense1'] = self.dense1.forward(params['dense1'], x, state['dense1'])\n",
    "        x, state['dense2'] = self.dense2.forward(params['dense2'], x, state['dense2'])\n",
    "        return x, state\n",
    "    \"\"\"\n",
    "\n",
    "seed = 4\n",
    "key = jax.random.key(seed)\n",
    "\n",
    "clf = Classifier()\n",
    "clf.init_params(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.switch_mode('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 - avg_loss: 15.675487518310547 \n",
      "epoch: 2 - avg_loss: 9.428189277648926 \n",
      "epoch: 3 - avg_loss: 7.113495826721191 \n",
      "epoch: 4 - avg_loss: 5.7458367347717285 \n",
      "epoch: 5 - avg_loss: 4.820437908172607 \n"
     ]
    }
   ],
   "source": [
    "loss_fn = CategoricalCrossEntropy(reduce_fn='mean_over_batch_size')\n",
    "optimizer = GradientDescent(lr=0.01, params=clf.params)\n",
    "\n",
    "def loss_fn_wrapped(method, params, x, y, state):\n",
    "    y_pred, new_state = method(params, x, state)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    return loss, new_state\n",
    "loss_and_grad = jax.value_and_grad(loss_fn_wrapped, argnums=1, has_aux=True)\n",
    "\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128    \n",
    "NUM_BATCHES = len(images) // BATCH_SIZE\n",
    "for epoch in range(EPOCHS):\n",
    "    total_losses = 0.0\n",
    "    for n in range(BATCH_SIZE): \n",
    "        (loss, new_state), gradients = loss_and_grad(clf.pure_forward, clf.params, images, targets_enc, clf.state)\n",
    "        new_params, optimizer.state = optimizer.step(clf.params, gradients, optimizer.state)            \n",
    "        clf.update_params(new_params)\n",
    "        clf.update_state(new_state)\n",
    "        total_losses += loss\n",
    "    print('epoch: {} - avg_loss: {} '.format(epoch+1, total_losses/NUM_BATCHES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.switch_mode('inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.940456\n",
      "Precision: 0.940922\n",
      "Recall   : 0.940144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "y_pred = clf(images).argmax(axis=1)\n",
    "accuracy = accuracy_score(targets, y_pred)\n",
    "precision = precision_score(targets, y_pred, average='macro')\n",
    "recall = recall_score(targets, y_pred, average='macro')\n",
    "print('Accuracy : {:<.6f}'.format(accuracy))\n",
    "print('Precision: {:<.6f}'.format(precision))\n",
    "print('Recall   : {:<.6f}'.format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ids are consistent. There are no copies of same items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params dense1:  True\n",
      "params dense2:  True\n",
      "state dense1:  True\n",
      "state dense2:  True\n"
     ]
    }
   ],
   "source": [
    "print('params dense1: ', _check_dict_ids(clf.params['dense1'], clf.layers['dense1'].params))\n",
    "print('params dense2: ', _check_dict_ids(clf.params['dense2'], clf.layers['dense2'].params))\n",
    "\n",
    "print('state dense1: ', _check_dict_ids(clf.state['dense1'], clf.layers['dense1'].state))\n",
    "print('state dense2: ', _check_dict_ids(clf.state['dense2'], clf.layers['dense2'].state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare to Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 13:26:55.048276: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-25 13:26:55.048336: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-25 13:26:55.048412: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-25 13:26:56.320679: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "targets_enc = keras.utils.to_categorical(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-25 13:26:57.359137: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "            keras.layers.Dense(32, use_bias=False),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Activation('relu'),\n",
    "            keras.layers.Dense(10, use_bias=False),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Activation('softmax'),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 4ms/step - loss: 101.6857\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 25.2509\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 14.6290\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 9.9063\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 7.1089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fc4571405d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0),\n",
    "    loss=keras.losses.CategoricalCrossentropy(reduction='sum')\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "        images, targets_enc,\n",
    "        epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/57 [..............................] - ETA: 5s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step\n",
      "Accuracy : 0.937117\n",
      "Precision: 0.952420\n",
      "Recall   : 0.936503\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(images).argmax(axis=1)\n",
    "targets = targets\n",
    "accuracy = accuracy_score(targets, y_pred)\n",
    "precision = precision_score(targets, y_pred, average='macro')\n",
    "recall = recall_score(targets, y_pred, average='macro')\n",
    "print('Accuracy : {:<.6f}'.format(accuracy))\n",
    "print('Precision: {:<.6f}'.format(precision))\n",
    "print('Recall   : {:<.6f}'.format(recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
